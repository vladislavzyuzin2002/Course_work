{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"private_outputs":true,"gpuType":"T4","authorship_tag":"ABX9TyMoKnAl/GKviGdgUDgt0wCL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install yfinance --quiet\n","!pip install pmdarima --quiet"],"metadata":{"id":"DH9b2jMz9MYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install statsmodels==0.11.0rc1 --quiet\n","!pip install -Iv pulp==1.6.8 --quiet"],"metadata":{"id":"CsQFLd5q9SKa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yfinance as yf\n","\n","# getting data from Yahoo Finance\n","stock_name = 'IBM' \n","data = yf.download(stock_name, start=\"2000-01-01\", end=\"2023-05-10\")"],"metadata":{"id":"WhIONP5K9hte"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import plotly\n","import plotly.graph_objs as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pmdarima as pm\n","plt.style.use('fivethirtyeight')\n","from pylab import rcParams\n","rcParams['figure.figsize'] = 10, 6\n","from statsmodels.tsa.arima_model import ARIMA\n","from pmdarima.arima import ADFTest\n","from pmdarima.datasets import load_wineind\n","import random"],"metadata":{"id":"X7OMwYQf92H7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Модель ARIMA"],"metadata":{"id":"CV9stAd_1ODz"}},{"cell_type":"code","source":["data_adf = data.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)\n","data_adf = data_adf['Close']\n","\n","from pmdarima.arima import ADFTest\n","adf_test = ADFTest(alpha = 0.05)\n","adf_test.should_diff(data_adf)"],"metadata":{"id":"V--ZAN6j-MaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def arima(stock_name, data):\n","    df_close = data['Close']\n","    \n","    # Split data into train and test set (90% - train, 10% - test)\n","    df_log = df_close\n","    train_data, test_data = df_log[3:int(len(df_log) * 0.9)], df_log[int(len(df_log) * 0.9 - 1):]\n","    test_values = len(df_log) * 0.01 + 1.0\n","    x_train = list(range(0, int(0.9*len(data))))\n","    x_test = list(range(int(0.9*len(data) - 1), int(len(data))))\n","    fig = go.Figure()\n","    fig.add_trace(go.Scatter(x=x_train, y=train_data, mode='lines+markers', marker=dict(size=4),  name='train', marker_color='#39304A'))\n","    fig.add_trace(go.Scatter(x=x_test, y=test_data, mode='lines+markers', marker=dict(size=4), name='test', marker_color='#A98D75'))\n","    fig.update_layout(legend_orientation=\"h\",\n","                  legend=dict(x=.5, xanchor=\"center\"),\n","                  plot_bgcolor='#FFFFFF',  \n","                  xaxis=dict(gridcolor = 'lightgrey'),\n","                  yaxis=dict(gridcolor = 'lightgrey'),\n","                  title_text = f'{stock_name} ARIMA data', title_x = 0.5,\n","                  xaxis_title=\"Timestep\",\n","                  yaxis_title=\"Stock price\",\n","                  margin=dict(l=0, r=0, t=30, b=0))\n","    fig.show()\n","    \n","    model =  pm.auto_arima(df_log,start_p=0, d=None, start_q=0, \n","                          max_p=2, max_d=2, max_q=2, start_P=0, \n","                          D=1, start_Q=0, max_P=2, max_D=2,\n","                          max_Q=2, m=7, seasonal=True, \n","                          error_action='warn',trace = True,\n","                          supress_warnings=True,stepwise = True,\n","                          random_state=20,n_fits = 50 )\n","\n","    model.summary()\n","\n","    exo_data = data['Volume']\n","    exo_data = exo_data[int(len(exo_data) * 0.9):]\n","    \n","    preds = model.predict(n_periods = 22, X = exo_data)\n","\n","    preds = np.vstack(preds)\n","    hist_data = yf.download(stock_name, start=\"2000-01-01\", end=\"2023-05-10\")\n","    hist_data = hist_data.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)\n","    hist_data = hist_data['Close']\n","    hist_data = np.array(hist_data)\n","    \n","    rmse = np.sqrt(np.mean(((preds - hist_data) ** 2)))\n","    print(f'RMSE ARIMA: {rmse}')\n","    \n","    # build graphs\n","    preds_gr = np.reshape(preds, (22,))\n","    fig = go.Figure()\n","    fig.add_trace(go.Scatter(x=list(range(0, 21)), y=hist_data, mode='lines+markers',  name='historical', marker_color='#39304A'))\n","    fig.add_trace(go.Scatter(x=list(range(0, 21)), y=preds_gr, mode='lines+markers', name='predictions', marker_color='#FFAA00'))\n","    fig.update_layout(legend_orientation=\"h\",\n","                  legend=dict(x=.5, xanchor=\"center\"),\n","                  plot_bgcolor='#FFFFFF',  \n","                  xaxis=dict(gridcolor = 'lightgrey'),\n","                  yaxis=dict(gridcolor = 'lightgrey'),\n","                  title_text = f'{stock_name} ARIMA prediction', title_x = 0.5,\n","                  xaxis_title=\"Timestep\",\n","                  yaxis_title=\"Stock price\",\n","                  margin=dict(l=0, r=0, t=30, b=0))\n","    fig.show()\n","\n","    return preds, rmse"],"metadata":{"id":"IILsJ2wZ-Tpt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arima_pred, arima_rmse = arima(stock_name, data)\n","print(arima_pred.shape)"],"metadata":{"id":"HdrXJkbX-ZMG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#SARIMAX"],"metadata":{"id":"Ogbed1Zz-qmI"}},{"cell_type":"code","source":["from statsmodels.tsa.statespace.sarimax import SARIMAX\n","data3 = data['Close']\n","    \n","# Split data into train and test set (90% - train, 10% - test)\n","train3_data, test3_data = data3[3:int(len(data3) * 0.9)], data3[int(len(data3) * 0.9):]\n","#test_values = len(data3) * 0.01 + 1.0\n","x_train = list(range(0, int(0.9*len(data))))\n","x_test = list(range(int(0.9*len(data)), int(len(data3))))\n","\n","exo_data = data['Volume']\n","exo_data = exo_data[int(len(exo_data) * 0.9):]\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=x_train, y=train3_data, mode='lines+markers', marker=dict(size=4),  name='train', marker_color='#39304A'))\n","fig.add_trace(go.Scatter(x=x_test, y=test3_data, mode='lines+markers', marker=dict(size=4), name='test', marker_color='#A98D75'))\n","fig.update_layout(legend_orientation=\"h\",\n","                  legend=dict(x=.5, xanchor=\"center\"),\n","                  plot_bgcolor='#FFFFFF',  \n","                  xaxis=dict(gridcolor = 'lightgrey'),\n","                  yaxis=dict(gridcolor = 'lightgrey'),\n","                  title_text = f'{stock_name} SARIMAX data', title_x = 0.5,\n","                  xaxis_title=\"Timestep\",\n","                  yaxis_title=\"Stock price\",\n","                  margin=dict(l=0, r=0, t=30, b=0))\n","fig.show()\n","    \n","model = SARIMAX(train3_data, order=(3, 1, 2))\n","\n","arima_model = model.fit(X = exo_data, disp=-1)\n","\n","print(arima_model.summary())\n","\n","\n","preds3 = arima_model.predict(n_periods=22, alpha=0.05)\n","\n","preds3 = np.vstack(preds3)\n","preds3 = preds3[-22:]\n","hist_data = yf.download(stock_name, start=\"1970-01-01\", end=\"2023-05-10\")\n","hist_data = hist_data.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)\n","hist_data = hist_data['Close']\n","hist_data = np.array(hist_data)\n","    \n","rmse = np.sqrt(np.mean(((preds3 - hist_data) ** 2)))\n","print(f'RMSE SARIMAX: {rmse}')\n","    \n","preds_gr = np.reshape(preds3, (22,))\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=list(range(0, 21)), y=hist_data, mode='lines+markers', name='historical', marker_color='#39304A'))\n","fig.add_trace(go.Scatter(x=list(range(0, 21)), y=preds_gr, mode='lines+markers', name='predictions', marker_color='#FFAA00'))\n","fig.update_layout(legend_orientation=\"h\",\n","                  legend=dict(x=.5, xanchor=\"center\"),\n","                  plot_bgcolor='#FFFFFF',  \n","                  xaxis=dict(gridcolor = 'lightgrey'),\n","                  yaxis=dict(gridcolor = 'lightgrey'),\n","                  title_text = f'{stock_name} SARIMAX prediction', title_x = 0.5,\n","                  xaxis_title=\"Timestep\",\n","                  yaxis_title=\"Stock price\",\n","                  margin=dict(l=0, r=0, t=30, b=0))\n","fig.show()"],"metadata":{"id":"xo3PxwXq-uoE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Модель экспоненциального сглаживания"],"metadata":{"id":"q-6Twp4mtyYZ"}},{"cell_type":"code","source":["%matplotlib inline\n","\n","import math\n","import matplotlib\n","import multiprocessing\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import time\n","\n","from collections import defaultdict\n","from datetime import date, datetime, timedelta\n","from joblib import Parallel, delayed\n","from matplotlib import pyplot as plt\n","from pylab import rcParams\n","\n","#### Input params ##################\n","H = 21\n","train_size = 252*3              # Use 3 years of data as train set. Note there are about 252 trading days in a year\n","val_size = 252                  # Use 1 year of data as validation set\n","\n","# alpha - smoothing coeff\n","alphaMax = 0.999\n","alphaMin = 0.01\n","alphaStep = 0.01\n","\n","# beta - trend coeff\n","betaMax = 0.999\n","betaMin = 0.01\n","betaStep = 0.01\n","\n","# gamma - seasonality coeff\n","gammaMax = 0.99\n","gammaMin = 0.1\n","gammaStep = 0.1   \n","\n","L = 252                        # seasonality period\n","\n","# for plot display\n","daysBackward = 30\n","daysForward = 60\n","\n","i_list = range(1008, 1008+84*5+42+1, 42) # we want to do a forecast on these days\n","\n","fontsize = 14\n","ticklabelsize = 14\n","####################################\n","\n","train_val_size = train_size + val_size # Size of train+validation set"],"metadata":{"id":"1nCdhBttWIn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yfinance as yf\n","\n","# getting data from Yahoo Finance\n","stock_name = 'IBM' \n","df = yf.download(stock_name, start=\"2000-01-01\", end=\"2023-05-10\").reset_index()"],"metadata":{"id":"vwDocTPTUr0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_mape(y_true, y_pred): \n","    \"\"\"\n","    Compute mean absolute percentage error (MAPE)\n","    \"\"\"\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","def get_mae(a, b):\n","    \"\"\"\n","    Comp mean absolute error e_t = E[|a_t - b_t|]. a and b can be lists.\n","    Returns a vector of len = len(a) = len(b)\n","    \"\"\"\n","    return np.mean(abs(np.array(a)-np.array(b)))\n","\n","def get_rmse(a, b):\n","    \"\"\"\n","    Comp RMSE. a and b can be lists.\n","    Returns a scalar.\n","    \"\"\"\n","    return math.sqrt(np.mean((np.array(a)-np.array(b))**2))\n","\n","def initial_trend(series, L):\n","    \"\"\"\n","    Initial trend, b_1 = ( (y_L+1 - y_1)/L + (y_L+2 - y_2)/L + ... + (y_L+L - y_L)/L ) / L\n","    \"\"\"\n","    sum = 0.0\n","    for i in range(L):\n","        sum += float(series[i+L] - series[i]) / L\n","        \n","    return sum / L\n","\n","def initial_seasonal_components(series, L):\n","    \"\"\"\n","    Initial seasonal index, \n","    I_t = ( y_t-A_1 + y_{t+L}-A_2 + ... + y_{t+(P-1)L}-A_P ) / P, \n","    t = 1, 2, ..., L\n","    Here P is the number of seasons we have in the series.\n","    For example, for sales data, we have 2018 Q1, 2018 Q2, 2018 Q3, 2018 Q4 data. These 4 points represent 1 season.\n","    A_1 is the mean of the values in the first season, and so on.\n","    Returns the seasonal components of length L in a list\n","    \"\"\"\n","    seasonals = []\n","    season_averages = []\n","    n_seasons = int(len(series)/L)\n","    \n","    # compute season averages\n","    for j in range(n_seasons):\n","        season_averages.append(sum(series[L*j:L*j+L])/float(L))\n","    \n","    # compute initial values\n","    for i in range(L):\n","        sum_of_vals_over_avg = 0.0\n","        for j in range(n_seasons):\n","            sum_of_vals_over_avg += series[L*j+i]-season_averages[j]\n","        seasonals.append(sum_of_vals_over_avg/n_seasons)\n","        \n","    return seasonals\n","\n","def triple_exponential_smoothing(series, L, H, alpha=0.3, beta=0.3, gamma=0.3, return_all=False):\n","    \"\"\"\n","    Overall smoothing:  S_t = alpha*(y_t - I_{t-L}) + (1-alpha)(S_{t-1} + b_{t-1}})\n","    Trend smoothing:    b_t = beta*(S_t - S_{t-1}) + (1-beta)*b_{t-1}\n","    Seasonal smoothing: I_t = gamma*(y_t - S_t) + (1-gamma)*I_{t-L}\n","    Forecast:           F_{t+m} = S_t + m*b_t + I_{t-L+m}, m >= 1\n","    Note here m has to be < len(series)\n","    result[len(series)] is the estimate of series[len(series)]\n","    The length of result is len(series) + H, where H >= 1\n","    \"\"\"\n","    result = [0, series[0]]\n","    smooth = series[0]\n","    trend = initial_trend(series, L)\n","    seasonals = initial_seasonal_components(series, L)\n","    seasonals.append(seasonals[0]) # To make the seasonals elements align with series elements\n","    for n in range(1, len(series)+H-1):\n","        if n >= len(series): # we are forecasting\n","            m = n - len(series) + 2\n","            result.append(smooth + m*trend + seasonals[n+1])\n","        else:\n","            val = series[n]\n","            last_smooth, smooth = smooth, alpha*(val-seasonals[n]) + (1-alpha)*(smooth+trend)\n","            trend = beta * (smooth-last_smooth) + (1-beta)*trend\n","            seasonals.append(gamma*(val-smooth) + (1-gamma)*seasonals[n])\n","            result.append(smooth + trend + seasonals[n+1])\n","            # e.g. result[2] uses series[1], seasonals[1], and seasonals[2]\n","            # ie. result[2] is the estimate of series[2]\n","            # e.g. result[len(series)] uses series[len(series)-1], seasonals[len(series)-1], and seasonals[len(series)] \n","            # ie. result[len(series)] is the estimate of series[len(series)]\n","            \n","    if return_all == True:\n","        return result, seasonals\n","    else:\n","        return result[len(series):len(series)+H], seasonals\n","\n","def get_error_metrics(series, train_size, L, H, alpha, beta, gamma):\n","    \"\"\"\n","    Given a series consisting of both train+validation, do predictions of forecast horizon H on the validation set, \n","    at H/2 intervals.\n","    Inputs\n","        series     : series to forecast, with length = (train_size + val_size)\n","        train_size : length of series to use as train ie. train set is series[:train_size]\n","        L          : period\n","        H          : forecast horizon\n","        alpha      : smoothing coeff\n","        beta       : trend coeff\n","        gamma      : seasonality coeff\n","    Outputs\n","        mean of rmse, mean of mape, mean of mae\n","    \"\"\"\n","    # Predict using single exponential smoothing, and compute error metrics also\n","    rmse = [] # root mean square error\n","    mape = [] # mean absolute percentage error\n","    mae = []  # mean absolute error\n","    preds_dict = {}\n","    \n","    for i in range(train_size, len(series)-H+1, int(H/2)):\n","        preds_list, seasonals = triple_exponential_smoothing(series[i-train_size:i], L, H, alpha, beta, gamma)\n","        \n","        rmse.append(get_rmse(series[i:i+H], preds_list))\n","        mape.append(get_mape(series[i:i+H], preds_list))\n","        mae.append(get_mae(series[i:i+H], preds_list))\n","        preds_dict[i] = preds_list\n","    \n","    return np.mean(rmse), np.mean(mape), np.mean(mae), preds_dict    \n","    \n","def hyperparam_tune_alpha_beta_gamma(series, train_size, L, H):\n","    \"\"\"\n","    Given a series, tune hyperparameter alpha, fit and predict\n","    Inputs\n","        series     : series to forecast, with length = (train_size + val_size)\n","        train_size : length of series to use as train ie. train set is series[:train_size]\n","        L          : period\n","        H          : forecast horizon\n","    Outputs\n","        optimum hyperparameters, error metrics dataframe\n","    \"\"\"\n","    err_dict = defaultdict(list)\n","    alpha = alphaMin\n","    while alpha <= alphaMax:\n","        beta = betaMin\n","        while beta <= betaMax:\n","            gamma = gammaMin\n","            while gamma <= gammaMax:\n","                rmse_mean, mape_mean, mae_mean, _ = get_error_metrics(series, train_size, L, H, alpha, beta, gamma)\n","        \n","                # Append alpha and beta\n","                err_dict['alpha'].append(alpha)\n","                err_dict['beta'].append(beta)\n","                err_dict['gamma'].append(gamma)\n","    \n","                # Compute error metrics\n","                err_dict['rmse'].append(rmse_mean)\n","                err_dict['mape'].append(mape_mean)\n","                err_dict['mae'].append(mae_mean)\n","                \n","                # Increase gamma by one step\n","                gamma = gamma + gammaStep\n","            \n","            # Increase beta by one step\n","            beta = beta + betaStep\n","        \n","        # Increase alpha by one step\n","        alpha = alpha + alphaStep\n","    \n","    # Convert to dataframe\n","    err_df = pd.DataFrame(err_dict)\n","    \n","    # Get min RMSE\n","    rmse_min = err_df['rmse'].min()\n","    \n","    return err_df[err_df['rmse'] == rmse_min]['alpha'].values[0], \\\n","           err_df[err_df['rmse'] == rmse_min]['beta'].values[0], \\\n","           err_df[err_df['rmse'] == rmse_min]['gamma'].values[0], \\\n","           err_df"],"metadata":{"id":"VjfTe5f8V7Fn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_error_metrics2(series, train_size, L, H, alpha, beta, gamma):\n","    \"\"\"\n","    Given a series consisting of both train+validation, do predictions of forecast horizon H on the validation set, \n","    at H/2 intervals.\n","    Inputs\n","        series     : series to forecast, with length = (train_size + val_size)\n","        train_size : length of series to use as train ie. train set is series[:train_size]\n","        L          : period\n","        H          : forecast horizon\n","        alpha      : smoothing coeff\n","        beta       : trend coeff\n","        gamma      : seasonality coeff\n","    Outputs\n","        mean of rmse, mean of mape, mean of mae\n","    \"\"\"\n","    # Predict using single exponential smoothing, and compute error metrics also\n","    rmse = [] # root mean square error\n","    mape = [] # mean absolute percentage error\n","    mae = []  # mean absolute error\n","    preds_dict = {}\n","    \n","    for i in range(train_size, len(series)-H+1, int(H/2)):\n","        preds_list, seasonals = triple_exponential_smoothing(series[i-train_size:i], L, H, alpha, beta, gamma)\n","        \n","        rmse.append(get_rmse(series[i:i+H], preds_list))\n","        mape.append(get_mape(series[i:i+H], preds_list))\n","        mae.append(get_mae(series[i:i+H], preds_list))\n","        preds_dict[i] = preds_list\n","    \n","    return np.mean(rmse), np.mean(mape), np.mean(mae), preds_dict, alpha, beta, gamma   \n","\n","def hyperparam_tune_alpha_beta_gamma_parallelized(series, train_size, L, H):\n","    \"\"\"\n","    This is a parallelized implementation of hyperparam_tune_alpha_beta_gamma_finetune.\n","    Given a series, tune hyperparameter alpha, fit and predict\n","    Inputs\n","        series     : series to forecast, with length = (train_size + val_size)\n","        train_size : length of series to use as train ie. train set is series[:train_size]\n","        L          : period\n","        H          : forecast horizon\n","    Outputs\n","        optimum hyperparameters, error metrics dataframe\n","    \"\"\"\n","    num_cores = multiprocessing.cpu_count()\n","    inputs = []\n","    alpha = alphaMin\n","    while alpha <= alphaMax:\n","        beta = betaMin\n","        while beta <= betaMax:\n","            gamma = gammaMin\n","            while gamma <= gammaMax:\n","                inputs.append((alpha, beta, gamma)) \n","                gamma = gamma + gammaStep\n","            beta = beta + betaStep\n","        alpha = alpha + alphaStep\n","        \n","    results = Parallel(n_jobs=num_cores)(delayed(get_error_metrics2)(series, train_size, L, H, item[0], item[1], item[2]) for item in inputs)\n","    # results has format [(rmse_mean1, mape_mean1, mae_mean1, preds_dict1, alpha1, beta1, gamma1), (rmse_mean2, mape_mean2, mae_mean2, preds_dict2, alpha2, beta2, gamma2), ...]   \n","    \n","    err_dict = defaultdict(list)\n","    for item in results:\n","        # Append error metrics\n","        err_dict['rmse'].append(item[0])\n","        err_dict['mape'].append(item[1])\n","        err_dict['mae'].append(item[2])\n","        \n","        # Append alpha and beta\n","        err_dict['alpha'].append(item[4])\n","        err_dict['beta'].append(item[5])\n","        err_dict['gamma'].append(item[6])\n","         \n","    # Convert to dataframe\n","    err_df = pd.DataFrame(err_dict)\n","    \n","    # Get min RMSE\n","    rmse_min = err_df['rmse'].min()\n","    \n","    alpha_opt = err_df[err_df['rmse'] == rmse_min]['alpha'].values[0]\n","    beta_opt = err_df[err_df['rmse'] == rmse_min]['beta'].values[0]\n","    gamma_opt = err_df[err_df['rmse'] == rmse_min]['gamma'].values[0]\n","    print(\"alpha_opt = \" + str(alpha_opt) + \n","          \", beta_opt = \" + str(beta_opt) + \n","          \", gamma_opt = \" + str(gamma_opt) + \n","          \", rmse_min = \" + str(rmse_min))\n","    \n","    return alpha_opt, beta_opt, gamma_opt, err_df"],"metadata":{"id":"idN5Yo91Wk95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert Date column to datetime\n","df.loc[:, 'Date'] = pd.to_datetime(df['Date'],format='%Y-%m-%d')\n","\n","# Change all column headings to be lower case, and remove spacing\n","df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n","\n","# Sort by datetime\n","df.sort_values(by='date', inplace=True, ascending=True)\n","\n","df.head(10)"],"metadata":{"id":"4kGlHSSDWoP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['date'].min(), df['date'].max() "],"metadata":{"id":"ZvrwP8_NWt-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot adjusted close over time\n","rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n","\n","ax = df.plot(x='date', y='adj_close', style='b-', grid=True)\n","ax.set_xlabel(\"date\")\n","ax.set_ylabel(\"USD\")"],"metadata":{"id":"EZtNWvJiWzET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 5000\n","# Predict\n","preds_list, seasonals = triple_exponential_smoothing(df['adj_close'][i-train_val_size:i].values, L, H, 0.3, 0.55, 0.6, True)\n","print(\"For forecast horizon %d, predicting on day %d, date %s, the RMSE is %f\" % (H, i, df['date'][i], get_rmse(df[i:i+H]['adj_close'], preds_list[train_val_size:train_val_size+H])))\n","print(\"For forecast horizon %d, predicting on day %d, date %s, the mean MAPE is %f\" % (H, i, df['date'][i], get_mape(df[i:i+H]['adj_close'], preds_list[train_val_size:train_val_size+H])))\n","print(\"For forecast horizon %d, predicting on day %d, date %s, the mean MAE is %f\" % (H, i, df['date'][i], get_mae(df[i:i+H]['adj_close'], preds_list[train_val_size:train_val_size+H])))"],"metadata":{"id":"tz624rPHW2Tv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the predictions\n","rcParams['figure.figsize'] = 15, 11 # width 10, height 8\n","matplotlib.rcParams.update({'font.size': 14})\n","ax = df.plot(x='date', y='adj_close', color='black', grid=True)\n","\n","# Plot the predictions\n","ax.plot(df['date'][i-train_val_size:i+H], preds_list, color='r')\n","ax.plot(df['date'][i:i+H], preds_list[train_val_size:train_val_size+H], color='blue')\n","    \n","ax.set_xlabel(\"date\")\n","ax.set_ylabel(\"USD\")\n","ax.legend(['adj_close', 'predictions'])\n","ax.set_ylim([min(min(preds_list[1:]), df[(df['date']>=df['date'][i]-timedelta(days=daysBackward)) & (df['date']<=df['date'][i]+timedelta(days=daysForward))]['adj_close'].min()), \n","             max(max(preds_list[1:]), df[(df['date']>=df['date'][i]-timedelta(days=daysBackward)) & (df['date']<=df['date'][i]+timedelta(days=daysForward))]['adj_close'].max())])\n","ax.set_xlim([df['date'][i-train_val_size+1], df['date'][i]+timedelta(days=H)])"],"metadata":{"id":"ZvCCATOuW-0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the seasonals\n","rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n","matplotlib.rcParams.update({'font.size': 14})\n","\n","plt.plot(seasonals)\n","plt.grid()"],"metadata":{"id":"BsZ9fjo8XeT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the seasonals with actual values on dual axes\n","fig, ax1 = plt.subplots()\n","\n","color = 'tab:red'\n","ax1.set_xlabel('date')\n","ax1.set_ylabel('USD', color=color)\n","ax1.plot(df['date'][:len(seasonals)], df['adj_close'][:len(seasonals)], color=color)\n","ax1.tick_params(axis='y', labelcolor=color)\n","\n","ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n","\n","color = 'tab:blue'\n","ax2.set_ylabel('seasonal components', color=color)  # we already handled the x-label with ax1\n","ax2.plot(df['date'][:len(seasonals)], seasonals, color=color)\n","ax2.tick_params(axis='y', labelcolor=color)\n","\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.grid()\n","plt.show()"],"metadata":{"id":"rWIycTvwYqZj"},"execution_count":null,"outputs":[]}]}